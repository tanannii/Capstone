{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45bf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import datetime as dt\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import csv\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee735e6d",
   "metadata": {},
   "source": [
    "# 1. Headcount Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a76995",
   "metadata": {},
   "source": [
    "## 1.1 Load Headcount Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fc5ff",
   "metadata": {},
   "source": [
    "### 1.1.1 Merge each month's data to get FY level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1f09583",
   "metadata": {},
   "outputs": [],
   "source": [
    "jun = pd.read_csv('./1. Data/Headcount/JUN HC.csv')\n",
    "jul = pd.read_csv('./1. Data/Headcount/JUL HC.csv')\n",
    "aug = pd.read_csv('./1. Data/Headcount/AUG HC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c95d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the dfs \n",
    "df = jun.append([jul, aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863fa29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567079, 114)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a87b8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get unique values by FY (sorted)\n",
    "#Sort by date\n",
    "df_sorted = df.sort_values(by='FISCAL_MONTH_END_DATE', ascending=True)\n",
    "\n",
    "#drop all the duplicates, keeping only the most recent row of the HC\n",
    "df_unique = df_sorted.drop_duplicates(subset=['EMAIL_ADDRESS'],  keep='last')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47c271",
   "metadata": {},
   "source": [
    "# 2. Change Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b337c",
   "metadata": {},
   "source": [
    "## 2.1 Load the change indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29105881",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.read_csv('./1. Data/Indicators/Change indicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2c75483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the counts for the indicator columns, use transform and sum\n",
    "\n",
    "col_list = ['ORG_CHANGE_INDICATOR','CAREER_LEVEL_CHANGE_INDICATOR','SUP_CHANGE_INDICATOR','JOB_CHANGE_INDICATOR',\n",
    "           'LOCATION_CHANGE_INDICATOR','SALARY_CHANGE_COUNT']\n",
    "\n",
    "\n",
    "#create a for loop to get all the columns that match the column list keyword\n",
    "for i in col_list:\n",
    "    fy_cols = df_fy_ind.filter(like=i).columns\n",
    "    fy2_cols = df_fy2_ind.filter(like=i).columns\n",
    "    \n",
    "    if len(fy_cols) > 0:\n",
    "        df_fy_ind[f'PFY_NUM_{i}'] = (df_fy_ind[fy_cols].groupby(df_fy_ind['EMAIL_ADDRESS']).transform('sum'))\n",
    "    \n",
    "    if len(fy2_cols) > 0:\n",
    "        df_fy2_ind[f'CFY_NUM_{i}'] = (df_fy2_ind[fy2_cols].groupby(df_fy2_ind['EMAIL_ADDRESS']).transform('sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6f81ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all the duplicates, keeping only the most recent row of the employee\n",
    "df_fy_ind2 = df_fy_ind.drop_duplicates(subset=['EMAIL_ADDRESS'],  keep='last')\n",
    "df_fy2_ind2 = df_fy2_ind.drop_duplicates(subset=['EMAIL_ADDRESS'],  keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55244fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the columns for merging\n",
    "\n",
    "df_fy_ind3 = df_fy_ind2[['EMAIL_ADDRESS','PFY_NUM_ORG_CHANGE_INDICATOR','PFY_NUM_CAREER_LEVEL_CHANGE_INDICATOR',\n",
    "                           'PFY_NUM_SUP_CHANGE_INDICATOR','PFY_NUM_JOB_CHANGE_INDICATOR','PFY_NUM_LOCATION_CHANGE_INDICATOR',\n",
    "                            'PFY_NUM_SALARY_CHANGE_COUNT']]\n",
    "\n",
    "df_fy2_ind3 = df_fy2_ind2[['EMAIL_ADDRESS','CFY_NUM_ORG_CHANGE_INDICATOR','CFY_NUM_CAREER_LEVEL_CHANGE_INDICATOR',\n",
    "                           'CFY_NUM_SUP_CHANGE_INDICATOR','CFY_NUM_JOB_CHANGE_INDICATOR','CFY_NUM_LOCATION_CHANGE_INDICATOR',\n",
    "                            'CFY_NUM_SALARY_CHANGE_COUNT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ffc88",
   "metadata": {},
   "source": [
    "## 2.2 Merge the change indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd45b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "698d765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_withIndicators = pd.merge(HC_unique, ind, on='EMAIL_ADDRESS',how ='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc737bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_withIndicators = pd.merge(HC_withIndicators, ind, on='EMAIL_ADDRESS',how ='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06c2193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66016, 126)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HC_withIndicators.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f09c8",
   "metadata": {},
   "source": [
    "# 3. Termination data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bff37a9",
   "metadata": {},
   "source": [
    "## 3.1 Load termination data and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d0c580a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load term data\n",
    "Term = pd.read_csv ('./1. Data/Attrition/Attrition.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd7ca0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Date Columns\n",
    "datecols = ['LATEST_HIRE_DATE','CONTINUOUS_SERVICE_DATE', 'TERMINATION_DATE', 'JOB_DATE', 'LAST_SALARY_INCR_DATE']\n",
    "\n",
    "#Convert all date columns to pandas datetime format\n",
    "term[datecols] = term[datecols].apply(pd.to_datetime, dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d39d932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by Termination Dates\n",
    "Termcols_sorted = Termcols.sort_values(by='LATEST_HIRE_DATE', ascending=True)\n",
    "\n",
    "\n",
    "#drop all the duplicates, keeping only the most recent row of the term\n",
    "# doing this ensures that only the most recent termination is considered for those rehire cases. Also, each terminated employee should only have one termination \n",
    "Termcols_unique = Termcols_sorted.drop_duplicates(subset=['EMAIL_ADDRESS'],  keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c61d3",
   "metadata": {},
   "source": [
    "## 3.2 Merge the termination data and the HC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ae4456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the HC data with Term data\n",
    "HC_Term = pd.merge(HC_withIndicators, Termcols_unique, on='EMAIL_ADDRESS',how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ab9a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column of 'Terminated' - to identify Active or Terminated\n",
    "HC_Term['TERMINATED'] = np.where(HC_Term['TERM_SUB_GROUP_TYPE_DESCRIPTION'].isnull(), 'ACTIVE', 'TERMINATED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27ac96",
   "metadata": {},
   "source": [
    "# 4. Survey Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a427c",
   "metadata": {},
   "source": [
    "## 4.1 Load and clean the Survey 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "177b7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey1 = pd.read_csv('./1. Data/Q3_clean_processed_datav2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a74fd5",
   "metadata": {},
   "source": [
    "## 4.2 Merge the survey1 scores with the HC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fb6b5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey1merge = pd.merge(survey1, hc, on='MANAGER_EMAIL_ADDRESS',how ='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272792d",
   "metadata": {},
   "source": [
    "# 5. Attainment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904bb71",
   "metadata": {},
   "source": [
    "## 5.1 Load and clean the attainment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "93a40dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sales attainment data\n",
    "df_attn = pd.read_csv('./1. Data/SalesAttainment/Attainment.csv',encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689a8ba",
   "metadata": {},
   "source": [
    "## 5.2 Merge the sales attainment data with the HC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b3ae6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged2 = pd.merge(df_attn, survey1merge, on='EMAIL_ADDRESS',how ='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47225c21",
   "metadata": {},
   "source": [
    "# 6. Manager Category Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2eb4ce",
   "metadata": {},
   "source": [
    "## 6.1 Load and merge the manager assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "772f47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mgr_ah = pd.read_csv('./1. Data/ManagerCategory/Assignment.csv',encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8c93fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged3 = pd.merge(merged2, df_mgr_ah, on='EMAIL_ADDRESS',how ='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f568341",
   "metadata": {},
   "source": [
    "# 7. Survey2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2c559",
   "metadata": {},
   "source": [
    "## 7.1 Load and clean Survey2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2aa53f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "df_survey2 = pd.read_excel('./1. Data/survey2/survey2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0df572",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged4 = pd.merge(merged3, df_survey2, on='EMAIL_ADDRESS',how ='left')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
